# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pFaAt2EugamBhhQ7FuvsceXmBc69JdPr
"""

import cv2

!pip install deepface

from deepface import DeepFace

img = cv2.imread('/content/download (3).jpeg')

import matplotlib.pyplot as plt

plt.imshow(img) #BGR

plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) #rgb

prediction = DeepFace.analyze(img)

prediction

type(prediction)

# Access the first element of the list (assuming it's a dictionary)
first_prediction = prediction[0]

# Then access the 'dominant_emotion' key within that dictionary
dominant_emotion = first_prediction['dominant_emotion']

print(dominant_emotion)

faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + '/content/haarcascade_frontalface_alt2.xml')

face_cascade_path = '/content/haarcascade_frontalface_alt2.xml'
faceCascade = cv2.CascadeClassifier(face_cascade_path)


if faceCascade.empty():
    print("Error loading face cascade classifier. Check the file path.")
else:
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    faces = faceCascade.detectMultiScale(gray, 1.1, 4)
    for (x, y, w, h) in faces:
        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)

plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))

font = cv2.FONT_HERSHEY_SIMPLEX
cv2.putText(img, dominant_emotion, (50, 50), font, 1, (0, 255, 0), 2, cv2.LINE_AA)

img =cv2.imread('/content/sad.jpeg')

plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))

prediction = DeepFace.analyze(img, enforce_detection=False)

prediction

"""IMAGE RECOGNITION

"""